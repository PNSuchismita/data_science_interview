{
 "metadata": {
  "name": "",
  "signature": "sha256:8c6a91e1d1eeced9d3b588ab5e218d48dd20b6f1510acbecb16c8cc703b632a3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "CS 562/662 (Natural Language Processing): \n",
      "\n",
      "Latent semantic analysis ([Kyle Gorman](gormanky@ohsu.edu))"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from re import findall\n",
      "from collections import Counter\n",
      "from numpy import allclose, diag, dot, zeros\n",
      "from numpy.linalg import norm, svd\n",
      "\n",
      "%pylab\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: MacOSX\n",
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the previous lecture we introduced the notion of a _term-document matrix_, which summarizes word coocurence statistics for multiple \"documents\". Each row $t_i$ in a term-document matrix represents a _term_ (i.e., a word or stem) and the frequency with which it occurs in each document. And, each column $d_j$ in such a matrix represents a _document_ and the frequency with which it employs each term. A term-document matrix thus contains a great deal of information about the associations between words and between documents (in the collection of documents that make it up)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More specifically (and wonkishly), given a term-document matrix $X$ with $T$ terms and $D$ documents:\n",
      "\n",
      "* the dot product of two rows of terms ($t{_i}{^T} t{_q}$) in $X$ is the correlation between terms $t_i$ and $t_j$, and the matrix $X X^T$ contains all such dot products\n",
      "* the dot product of two columns of documents ($d{_j}{^T} d{_q}$) in $X$ is the correlation between two documents, and the matrix $X^T X$ contains all such dot products"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_Latent semantic analysis_ (LSA), also sometimes known as _latent semantic indexing_ (LSI), is a method to exploit information in term-document matrices using first principles from linear algebra. In particular, we use dimensionality reduction techniques to create a much-reduced form of the term-document matrix, and then use this to project terms and documents into a low-dimensionality \"topic space\", in which we can perform basic clustering and comparison of both terms and documents."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Constructing a term-document matrix"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following example comes from Deeerwester et al. 1990. The first set of \"documents\" (actually, paper titles) are related to human-computer interaction (HCI), and the second are related to graph theory. We assume that terms which are not \"underlined\" (e.g., `_term_`) are filtered out (as stopwords or due to low term or document frequency.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# HCI-related documents\n",
      "c0 = \"\"\"\n",
      "_Human_ machine _interface_ for Lab ABC _computer_ applications\n",
      "A _survey_ of _user_ opinion of _computer_ _system_ _response_ _time_\n",
      "The _EPS_ _user_ _interface_ management _system_\n",
      "_System_ and _human_ _system_ engineering testing of _EPS_\n",
      "Relation of _user_-perceived _response_ _time_ to error measurement\n",
      "\"\"\"\n",
      "# Graph-theory-related documents\n",
      "c1 = \"\"\"\n",
      "The generation of random binary unordered _trees_\n",
      "The intersection _graph_ of paths in _trees_\n",
      "_Graph_ _minors_ IV: Widths of _trees_ and well-quasi-ordering\n",
      "_Graph_ _minors_: A _survey_\n",
      "\"\"\"\n",
      "\n",
      "def prep_corpus(lines):\n",
      "    \"\"\"\n",
      "    Given `lines` (a string) of text, generate the corresponding\n",
      "    corpus (a list of \"documents\", where each document is a list \n",
      "    of terms\n",
      "    \"\"\"\n",
      "    for line in lines.split(\"\\n\"):\n",
      "        # ignore empty lines\n",
      "        if not line:\n",
      "            continue\n",
      "        yield [term.upper() for term in findall(r\"_(.*?)_\", line)]\n",
      "    \n",
      "corpus = prep_corpus(c0 + c1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following function constructs a dense (i.e., full-rank) term-document matrix from the `corpus` object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def termdoc_index(corpus):\n",
      "    \"\"\"\n",
      "    Given a `corpus` (a list of documents, which are themselves \n",
      "    lists of terms), return a dense term-document matrix and a \n",
      "    term index\n",
      "    \n",
      "    Many things you might do (such as filter by DF or TF) are not\n",
      "    implemented here\n",
      "    \"\"\"\n",
      "    # collect sparse frequencies\n",
      "    terms = set() # to populate a term index\n",
      "    termdoc_sparse = [] # to populate dense a t-d matrix\n",
      "    for doc in corpus:\n",
      "        # compute term frequencies for this document\n",
      "        column_sparse = Counter(doc)\n",
      "        # save term frequencies\n",
      "        termdoc_sparse.append(column_sparse)\n",
      "        # add new terms to term set\n",
      "        terms.update(column_sparse.iterkeys())\n",
      "    # convert term set to index\n",
      "    index = {term: i for (i, term) in enumerate(terms)}\n",
      "    # build dense matrix\n",
      "    termdoc_dense = zeros((len(terms), len(termdoc_sparse)))\n",
      "    for (j, column_sparse) in enumerate(termdoc_sparse):\n",
      "        # a pointer to a column in the term-document matrix:\n",
      "        column_dense = termdoc_dense[:, j]\n",
      "        for (term, freq) in column_sparse.iteritems():\n",
      "            i = index[term]\n",
      "            column_dense[i] = freq\n",
      "            # equivalently: `termdoc_dense[i, j] = freq`\n",
      "    return (termdoc_dense, index)\n",
      "\n",
      "(X, index) = termdoc_index(corpus)\n",
      "print(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.  0.  0.  0.  0.  0.  0.  1.  1.]\n",
        " [ 0.  0.  0.  0.  0.  0.  1.  1.  1.]\n",
        " [ 0.  1.  1.  2.  0.  0.  0.  0.  0.]\n",
        " [ 0.  0.  0.  0.  0.  1.  1.  1.  0.]\n",
        " [ 0.  0.  1.  1.  0.  0.  0.  0.  0.]\n",
        " [ 1.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
        " [ 0.  1.  0.  0.  0.  0.  0.  0.  1.]\n",
        " [ 0.  1.  1.  0.  1.  0.  0.  0.  0.]\n",
        " [ 1.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
        " [ 0.  1.  0.  0.  1.  0.  0.  0.  0.]\n",
        " [ 1.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
        " [ 0.  1.  0.  0.  1.  0.  0.  0.  0.]]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll also hold on to some pointers to terms and documents, for later."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t_human = X[index[\"HUMAN\"], :]\n",
      "t_user = X[index[\"USER\"], :]\n",
      "t_graph = X[index[\"GRAPH\"], :]\n",
      "d_ABC = X[:, 0]\n",
      "d_response = X[:, 4]\n",
      "d_survey = X[:, 8]\n",
      "print t_graph  # \"GRAPH\" occurs only in the graph-theory corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.  0.  0.  0.  0.  0.  1.  1.  1.]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Dimensionality reduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One problem when working in a larger scale (than this toy example) is that the dense term-document matrix grows very rapidly, even if we remove terms with low term frequency or low document frequency. So we wish to generate a low-rank approximation of this matrix. This is accomplished using a matrix factorization technique known as _singular value decomposition_ defined as follows. The singular value decomposition of a matrix $X$ is given by three matrices $U$, $\\Sigma$, and $V$ such that\n",
      "\n",
      "$$\\hat{X} = U \\Sigma V^T$$ \n",
      "\n",
      "where $U$, $\\Sigma$, and $V$ are all matrices. **In other words, $X$ can be approximated by the product of three square matrices.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(U, Sigma_diag, V) = svd(X, full_matrices=False)\n",
      "Sigma = diag(Sigma_diag)\n",
      "print allclose(X, dot(U, dot(Sigma, V)))  # not a bad approximation!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this decomposition, $U$ is a orthogonal matrix; $\\Sigma$ is a diagonal square matrix; $V$ is a orthogonal square matrix with the dimensionality determined by the number of documents."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"U dimensionality:\\t{}\".format(U.shape)\n",
      "print \"Sigma dimensionality:\\t{}\".format(Sigma.shape)\n",
      "print \"V dimensionality:\\t{}\".format(V.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "U dimensionality:\t(12, 9)\n",
        "Sigma dimensionality:\t(9, 9)\n",
        "V dimensionality:\t(9, 9)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, the dimensionality of the SVD approximation grows quadratically both in the number of terms and number of documents. However, we can hold this constant by throwing away all but first $k$ terms in the approximation. This results in a new approximation \n",
      "\n",
      "$$\\hat{X_k} = U_k \\Sigma_k V{_k}{^T}$$ \n",
      "\n",
      "which is known to be the optimal $k$-dimensional approximation. Here, we will use $k = 2$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k = 2\n",
      "U_k = U[:, :k]\n",
      "# Sigma_diag is just an array...and going forward, \n",
      "# we only need its inverse, so we'll compute that\n",
      "invSigma_k = diag(1. / Sigma_diag[:k])\n",
      "# equivalently, `inv(diag(Sigma[:k]))`\n",
      "V_k = V[:, :k]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "The \"topic space\" translation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now translate each document into the $k$-dimensional \"topic space\" as follows. If $d_j$ is a document column in $X$, then \n",
      "\n",
      "$$\\hat{d_j} = {\\Sigma_k}^{-1} U{_k}{^T} d_j~.$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def doc_translate(d, U_k, invSigma_k):\n",
      "    \"\"\"\n",
      "    Translate a document `t` into a topic space U \\Sigma V.\n",
      "    We tranpose `d` because numpy forgets that it's really a column\n",
      "    vector.\n",
      "    \"\"\"\n",
      "    return dot(dot(invSigma_k, U_k.T), d.T)\n",
      "\n",
      "v_ABC = doc_translate(d_ABC, U_k, invSigma_k)\n",
      "v_response = doc_translate(d_response, U_k, invSigma_k)\n",
      "v_survey = doc_translate(d_survey, U_k, invSigma_k)\n",
      "print(v_ABC)\n",
      "print(v_response)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-0.1973928  -0.05591352]\n",
        "[-0.27946911  0.10677472]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The same can be done for novel queries; we simply treat each query $d_q$ as if it were a new document and apply the same translation."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We also can translate terms into topic space. If $t_i$ is a term row in $X$, then\n",
      "                                                              \n",
      "$$\\hat{t_i} = {\\Sigma_k}^{-1} V{_k}{^T} t_i~.$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def term_translate(t, invSigma_k, V_k):\n",
      "    \"\"\"\n",
      "    Translate a term `t` into a topic space U_k \\Sigma_k V_k \n",
      "    \"\"\"\n",
      "    return dot(dot(invSigma_k, V_k.T), t)\n",
      "\n",
      "v_human = term_translate(t_human, invSigma_k, V_k)\n",
      "v_user = term_translate(t_user, invSigma_k, V_k)\n",
      "v_graph = term_translate(t_graph, invSigma_k, V_k)\n",
      "print(v_human)\n",
      "print(v_user)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-0.34337556 -0.24969073]\n",
        "[ 0.02994261 -0.21169323]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Similarity in topic space"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Most importantly, we can compare pairs of vectors in the topic space $v_0$, $v_1$, regardless of their source (terms, queries, or documents). We take the relatedness of two topic-space vector to be monotonically related to the angle between the two vectors $\\theta$. More specifically, we compute the cosine of this angle, a measure called _cosine similarity_, which is defined as \n",
      "\n",
      "$$cos~\\theta = \\frac{v_0~\\cdot~v_1}{\\|v_0\\| \\|v_1\\|}$$\n",
      "\n",
      "where $\\|v\\|$ represents the Euclidean norm of the vector $v$. The value of this measure lines in $[-1, 1]$, where $1$ indicates vector identity and $-1$ indicates maximal vector dissimilarity."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cosine_similarity(v0, v1):\n",
      "    \"\"\"\n",
      "    Compute cosine similarity between two vectors `v0`, `v1`\n",
      "    \"\"\"\n",
      "    numerator = dot(v0, v1)\n",
      "    denominator = norm(v0) * norm(v1)\n",
      "    return numerator / denominator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use this measure to estimate  document and term similarities. As expected, the HCI terms and documents are more similar to each other than they are to graph-theory terms and documents, respectively."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# term similarities\n",
      "print \"HUMAN v. USER:\\t{: .4f}\".format(cosine_similarity(v_human, v_user))\n",
      "print \"HUMAN v. GRAPH:\\t{:.4f}\".format(cosine_similarity(v_human, v_graph))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "HUMAN v. USER:\t 0.4690\n",
        "HUMAN v. GRAPH:\t-0.1364\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# document similarities\n",
      "print \"'ABC' article v. 'RESPONSE' article:\\t{: .4f}\".format(\n",
      "      cosine_similarity(v_ABC, v_response))\n",
      "print \"'ABC' article v. 'SURVEY' article:\\t{: .4f}\".format(\n",
      "      cosine_similarity(v_ABC, v_survey))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "'ABC' article v. 'RESPONSE' article:\t 0.8015\n",
        "'ABC' article v. 'SURVEY' article:\t-0.1223\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When $k = 2$, we can also visualize terms and documents using a Cartesian coordinates. (In practice, we usually choose a much larger value of $k$.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_2d_translations(translations):\n",
      "    plot([0, 0], [0, 0], \".\")\n",
      "    for translation in translations:\n",
      "        plot([0, translation[0]], [0, translation[1]], \"-\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_2d_translations([v_human, v_user, v_graph])\n",
      "# green: 'HUMAN'\n",
      "# red: 'USER'\n",
      "# cyan: 'GRAPH'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\negAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x106b84790>"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_2d_translations([v_ABC, v_response, v_survey])\n",
      "# green: 'ABC'\n",
      "# red: 'RESPONSE'\n",
      "# cyan: 'SURVEY'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x106c6b650>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Efficient and feasible LSA"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A limitation of the LSA method illustrated above is that the na\u00efve approach requires a full-rank term-document matrix which fits in memory; though this matrix is relatively sparse, the dense variant often grows on both dimensions every time a new document is entered! However, there exist many incremental (i.e., one document at a time) approximations of SVD, and one fast variant (Brand 2006) is implemented in the [Gensim](https://radimrehurek.com/gensim/) library (\u0158eh\u016f\u0159ek and Sojka 2010)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "References"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "M. Brand. 2006. Fast low-rank modifications of the thin singular value decomposition. _Linear Algebra and its Applications_ 415(1): 20-30.\n",
      "\n",
      "S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer, and R. Harshman. 1990. Indexing by latent semantic analysis. 190. _Journal of the American Society for Information Science_ 41(6): 391-407.\n",
      "\n",
      "R. \u0158eh\u016f\u0159ek and P. Sojka. 2010. Software framework for topic modelling with large corpora. In _LREC_, 45-50."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}